% Template for ICIP-2019 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}

\newcommand{\dlt}[1]{{}}
\newcommand{\cxj}[1]{\textcolor{red}{(Cxj: #1)}}
% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{EFFECT OF INSTANCE NORMALIZATION ON FINE-GRAINED CONTROL FOR SKETCH-BASED FACE IMAGE GENERATION}
%
% Single address.
% ---------------
\name{Zhihua Cheng, Binxin Yang, Zihan Chen, Xuejin Chen}
\address{University of Science and Technology of China, China}
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\graphicspath{{figures/}}  % 图片存放路径

\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
Sketching is an intuitive and effective way for content creation. While significant progress has been made for photorealistic image generation by using generative adversarial networks, it remains challenging to make fine-grained controls on the synthetic content. 
%Instance normalization, which is widely adopted in image translation networks, washes away details in the input sketch and leads to loss of precise control on the desired shape of the generated face images.
In this paper, we comprehensively investigate the effect of instance normalization on generating photorealistic face images from hand-drawn sketches.
We first introduce a visualization pipeline to analyze the feature embedding for sketches with a group of specific changes.  
Based on the visual analysis, we modify the instance normalization layers in the baseline model. 
We elaborate a new set of hand-drawn sketches with 11 categories of specially designed changes and conduct extensive experimental analysis.  The results and user studies demonstrate that our method markedly improves the quality of synthesized images and the conformance with user intention.

\end{abstract}
%
\begin{keywords}
Sketch, face generation, instance normalization, fine-grained control, GAN
\end{keywords}
%
\section{Introduction}
\label{sec:intro}

Photorealistic face image synthesis from hand-drawn sketches using generative adversarial networks~(GANs)~\cite{gan} has drawn a lot of attention in computer graphics and computer vision recently. Considering hand-drawn sketches as one specific type of images, generating face images from sketches can be formulated as an image-to-image translation problem, which generates corresponding image in one domain from an image in another domain while the two images share the same structure~\cite{cyclegan,bicyclegan,spagan,munit,crn,cfgan,sis,maskgan}.
The concept of image-to-image translation was first proposed by pix2pix~\cite{pix2pix} and was applied to a variety of image translation scenarios, such as label maps to streetscapes, edge maps to photos, image colorization, and so on.
%However, the original pix2pix model has limits of low resolution images, at most $256 \times 256$. 
In order to improve the resolution of synthesized images, a subsequent model, pix2pixHD~\cite{pix2pixhd}, is proposed to generate images from semantic label maps by a coarse-to-fine generator and a multiscale discriminator. 
However, the instance normalization layers used in pix2pixHD tend to wash away semantic information.
In order to efficiently preserve and propagate semantic information throughout the network, GauGAN~\cite{spade} utilizes semantic segmentation masks to modulate activations in the normalization layers through a spatially-adaptive and learned transformation. 
%
These models can also be applied to edge-to-photo generation when conditioned on edge maps and photo pairs.
%\cite{} \cxj{Add references here}. 

However, the large gap between synthesized edge maps and hand-drawn sketches challenges the generalization ability of these models.
%It inspires us to investigate the effect of normalization layers more deeply on information propagation in the network architecture for sketch-based face image synthesis.


In various GANs, normalization layers play an important role for stabilizing the training process. 
%Many normalization layers have been developed, such as batch normalization~\cite{bn}, group normalization~\cite{gn}, layer normalization~\cite{ln}, and instance normalization~\cite{instance_norm}. 
Batch normalization~\cite{bn} eliminates the influence of internal covariate shift and effectively speeds up the training time. 
Group normalization~\cite{gn} organizes the channels of a layer into different groups, and computes the mean and standard deviation within each group independently for normalization. It is independent of batch size thus frequently used in tasks that prefer small mini-batch size, such as object detection and video classification.
Layer normalization~\cite{ln} computes the mean and variance used for normalization over all the channels of a single layer. It is more suitable for recurrent neural networks. 
%Layer normalization performs exactly the same computation at training and test times.
Instance normalization~\cite{instance_norm} is similar to layer normalization but goes one step further. It computes the mean and variance for normalization over \emph{each} channel in \emph{each} training example.
Recent studies show that instance normalization performs well on visual tasks such as style transfer and image translation~\cite{pix2pixhd,spade,cyclegan} when replacing the batch normalization in GAN architecture. 
Nonetheless, instance normalization layers tend to wash away detailed information conveyed by the input sketches, thus it results in descent of the feature expression ability and imprecise control on face generation. 
 
It is essential to support fine-grained control in sketch-based content creation. 
We comprehensively investigate the effect of instance normalization on fine-grained control in sketch-based photorealistic face image generation. 
We utilize principal component analysis (PCA)~\cite{pca} to visualize and analyze features extracted from sketches by the generator. 
Consequently, we propose to remove the first two instance normalization layers in the baseline generator.
% and show that this simple modification in the generator results in a significant improvement on fine-grained control in image generation. 
We conduct extensive experiments and user studies to evaluate our proposed method. The results demonstrate that our method surpasses the baseline method on image quality and control precision on the sketch-to-image task.

\input{method}

\input{result}


% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
